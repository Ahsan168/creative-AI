{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8967028,"sourceType":"datasetVersion","datasetId":5397932},{"sourceId":8969470,"sourceType":"datasetVersion","datasetId":5399724},{"sourceId":9060488,"sourceType":"datasetVersion","datasetId":5463880},{"sourceId":87035,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":73101,"modelId":97985}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install datasets\n# !pip install datasets transformers\n!pip install datasets transformers peft\n# !pip install transformers tensorflow\n!pip install langchain transformers datasets peft tensorflow\n!pip install langchain-community","metadata":{"execution":{"iopub.status.busy":"2024-08-01T19:54:02.210618Z","iopub.execute_input":"2024-08-01T19:54:02.211223Z","iopub.status.idle":"2024-08-01T19:54:58.958440Z","shell.execute_reply.started":"2024-08-01T19:54:02.211188Z","shell.execute_reply":"2024-08-01T19:54:58.956825Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.20.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\nCollecting peft\n  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.32.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.12.0\nCollecting langchain\n  Downloading langchain-0.2.11-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.20.0)\nRequirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.12.0)\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nCollecting langchain-core<0.3.0,>=0.2.23 (from langchain)\n  Downloading langchain_core-0.2.26-py3-none-any.whl.metadata (6.2 kB)\nCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\nCollecting langsmith<0.2.0,>=0.1.17 (from langchain)\n  Downloading langsmith-0.1.95-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.32.1)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.60.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nCollecting keras<2.16,>=2.15.0 (from tensorflow)\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (1.33)\nCollecting packaging>=20.0 (from transformers)\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m980.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.7.4)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain) (2.4)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\nDownloading langchain-0.2.11-py3-none-any.whl (990 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.3/990.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain_core-0.2.26-py3-none-any.whl (378 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.9/378.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\nDownloading langsmith-0.1.95-py3-none-any.whl (275 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.8/275.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, orjson, keras, langsmith, langchain-core, langchain-text-splitters, langchain\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: orjson\n    Found existing installation: orjson 3.9.10\n    Uninstalling orjson-3.9.10:\n      Successfully uninstalled orjson-3.9.10\n  Attempting uninstall: keras\n    Found existing installation: keras 3.4.1\n    Uninstalling keras-3.4.1:\n      Successfully uninstalled keras-3.4.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.6.1 requires cubinlinker, which is not installed.\ncudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.6.1 requires ptxcompiler, which is not installed.\ncuml 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.9.0 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\ncudf 24.6.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\ndistributed 2024.5.1 requires dask==2024.5.1, but you have dask 2024.7.0 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\njupyterlab 4.2.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nrapids-dask-dependency 24.6.0a0 requires dask==2024.5.1, but you have dask 2024.7.0 which is incompatible.\nspaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0 langchain-0.2.11 langchain-core-0.2.26 langchain-text-splitters-0.2.2 langsmith-0.1.95 orjson-3.10.6 packaging-24.1\nCollecting langchain-community\n  Downloading langchain_community-0.2.10-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (3.9.1)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.6.7)\nRequirement already satisfied: langchain<0.3.0,>=0.2.9 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.2.11)\nRequirement already satisfied: langchain-core<0.3.0,>=0.2.23 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.2.26)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.1.95)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (8.2.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.9->langchain-community) (0.2.2)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.9->langchain-community) (2.5.3)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain-community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain-community) (24.1)\nRequirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain-community) (4.9.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2024.7.4)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain-community) (2.4)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain-community) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain-community) (2.14.6)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nDownloading langchain_community-0.2.10-py3-none-any.whl (2.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: langchain-community\nSuccessfully installed langchain-community-0.2.10\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\")\n\ntokenizer = AutoTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\")\nmodel = AutoModelForCausalLM.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\", device_map={\"\":0}, torch_dtype=torch.float16)\n\nlora_config = LoraConfig.from_pretrained('/kaggle/input/fine-tuned-model2')\nmodel = get_peft_model(model, lora_config)\n\n# Initialize pipeline\ntext_generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\nfrom transformers import pipeline\n\n# Load pre-trained emotion classifier\nemotion_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\nemotion_model = TFAutoModelForSequenceClassification.from_pretrained(\"AaronMarker/emotionClassifier\", num_labels=9)\nemotion_classifier = pipeline(\"text-classification\", model=emotion_model, tokenizer=emotion_tokenizer)\n\n# Define the emotion mapping\nemotions = {\n    'LABEL_0': 'Joy',\n    'LABEL_1': 'Desire',\n    'LABEL_2': 'Admiration',\n    'LABEL_3': 'Approval',\n    'LABEL_4': 'Curiosity',\n    'LABEL_5': 'Fear',\n    'LABEL_6': 'Sadness',\n    'LABEL_7': 'Anger',\n    'LABEL_8': 'Neutral'\n}\n\n# Function to predict emotion\ndef predict_emotion(sentence):\n    prediction = emotions[emotion_classifier(sentence)[0][\"label\"]]\n    return prediction\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Manual check**","metadata":{}},{"cell_type":"code","source":"import torch\n\n# Assuming 'tokenizer' and 'model' are defined and 'device' is set to 'cuda:0'\ndevice = torch.device('cuda:0')\n\nuser_input = \"Tell me a funny story.\"\nmood = predict_emotion(user_input)\nprint(f'Analyzed mood: {mood}')\n\n# Tokenize input\ninputs = tokenizer(f\"You are a creative story assistant. Your task is to tell me stories and help me in story writing. Stick to the context of story creativity. If I ask anything out of context, other than story generation or writing, politely inform me that you can only help with story-related queries and don't say anything else! Provide detailed and imaginative responses to me. My mood is: {mood} and I'm asking: {user_input}\", return_tensors=\"pt\")\n\n# Ensure input_ids is on the same device as model\ninput_ids = inputs['input_ids'].to(device)\n\n# # Move model to CUDA if not already there\n# model.to(device)\n\n# Generate output\nwith torch.no_grad():\n    outputs = model.generate(input_ids=input_ids, max_new_tokens=1000)\n\ndecoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprint(decoded_output)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **LangChain without context**","metadata":{}},{"cell_type":"code","source":"from langchain import LLMChain, PromptTemplate\nfrom langchain.memory.buffer import ConversationBufferMemory\nfrom langchain.schema.runnable import RunnablePassthrough\nfrom langchain_core.output_parsers import StrOutputParser\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nfrom langchain import HuggingFacePipeline, PromptTemplate, LLMChain\nfrom peft import PeftModel, PeftConfig\nimport torch\n\nclass StoryCreativityChain:\n    def __init__(self, model, tokenizer):\n       \n        self.llmPipeline = pipeline(\"text-generation\",\n                                    model=model,\n                                    tokenizer=tokenizer,\n                                    torch_dtype=torch.float16,\n                                    device_map=\"auto\",\n                                    max_new_tokens=1000,\n                                    do_sample=True,\n                                    top_k=30,\n                                    num_return_sequences=1,\n                                    eos_token_id=tokenizer.eos_token_id\n                                    )\n        self.llm = HuggingFacePipeline(pipeline=self.llmPipeline, model_kwargs={'temperature': 0.7, 'max_length': 5, 'top_k': 50})\n        \n    def getPromptFromTemplate(self):\n        system_prompt = \"\"\"You are a creative story assistant. Your task is to help the user generate and write stories.\n        Stick to the context of story creativity. If the user asks anything out of context, other than story generation or writing, politely inform them that you\n        can only help with story-related queries and cannot help with anything else. Don't answer anything out of context. Provide detailed and imaginative responses to help the user.\"\"\"\n\n        B_INST, E_INST = \"[INST]\", \"[/INST]\"\n        B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n        SYSTEM_PROMPT1 = B_SYS + system_prompt + E_SYS\n\n        instruction = \"\"\"\n        History: {history} \\n\n        User: {question}\"\"\"\n\n        prompt_template = B_INST + SYSTEM_PROMPT1 + instruction + E_INST\n        prompt = PromptTemplate(input_variables=[\"history\", \"question\"], template=prompt_template)\n\n        return prompt\n\n    def getNewChain(self, usermood):\n        prompt = self.getPromptFromTemplate()\n        memory = ConversationBufferMemory(input_key=\"question\", memory_key=\"history\", max_len=5)\n\n        # Initialize LLMChain with proper parameters\n        llm_chain = LLMChain(prompt=prompt, llm=self.llm, verbose=True, memory=memory, output_parser=CustomOutputParser())\n\n        # Return a callable that processes inputs using the chain\n        def run_chain(inputs):\n            # Ensure the inputs are correctly provided\n#             context = inputs.get(\"context\", \"\")\n            question = inputs.get(\"question\", \"\")\n            return llm_chain.run({\"history\": \"\", \"question\": question})\n\n        return run_chain\n\nclass CustomOutputParser(StrOutputParser):\n    def parse(self, response: str):\n        return response.split('[/INST]')[-1].strip()\n\nif __name__ == \"__main__\":\n    user_input = \"Tell me a funny story\"\n#     \"Can you tell me recipe of pasta?\"\n    mood = predict_emotion(user_input)  # Replace with actual mood detection logic\n    print(f'Analyzed mood: {mood}')\n    \n    story_chain = StoryCreativityChain(model, tokenizer)\n    chain = story_chain.getNewChain(mood)\n\n    # Simulate user interaction\n    response = chain({\"question\": user_input})\n    print(f'Generated story: {response}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"response = chain({\"question\": \"a silly animal adventure\"})\nprint(f'Generated story: {response}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Front-end**","metadata":{"execution":{"iopub.execute_input":"2024-07-22T10:09:03.907886Z","iopub.status.busy":"2024-07-22T10:09:03.907475Z","iopub.status.idle":"2024-07-22T10:09:03.912444Z","shell.execute_reply":"2024-07-22T10:09:03.911563Z","shell.execute_reply.started":"2024-07-22T10:09:03.907854Z"}}},{"cell_type":"markdown","source":"## **ChainLit**","metadata":{}},{"cell_type":"code","source":"!pip install chainlit","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile chainlit_app.py\n\nimport chainlit as cl\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nfrom langchain import LLMChain, PromptTemplate\nfrom langchain.memory.buffer import ConversationBufferMemory\nfrom langchain.schema.runnable import RunnablePassthrough\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain import HuggingFacePipeline, PromptTemplate, LLMChain\nfrom peft import PeftModel, PeftConfig\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\nfrom transformers import pipeline\nfrom datasets import Dataset\nfrom peft import LoraConfig, get_peft_model\nimport pandas as pd\nimport torch\n\nclass StoryCreativityChain:\n    def __init__(self, model, tokenizer):\n        self.llmPipeline = pipeline(\n            \"text-generation\",\n            model=model,\n            tokenizer=tokenizer,\n            torch_dtype=torch.float16,\n            device_map=\"auto\",\n            max_new_tokens=1000,\n            do_sample=True,\n            top_k=30,\n            num_return_sequences=1,\n            eos_token_id=tokenizer.eos_token_id\n        )\n        self.llm = HuggingFacePipeline(pipeline=self.llmPipeline, model_kwargs={'temperature': 0.7, 'max_length': 5, 'top_k': 50})\n\n    def getPromptFromTemplate(self):\n        system_prompt = \"\"\"You are a creative story assistant. Your task is to help the user generate and write stories.\n        Stick to the context of story creativity. If the user asks anything out of context, other than story generation or writing, politely inform them that you\n        can only help with story-related queries and cannot help with anything else. Don't answer anything out of context. Provide detailed and imaginative responses to help the user.\"\"\"\n\n        B_INST, E_INST = \"[INST]\", \"[/INST]\"\n        B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n        SYSTEM_PROMPT1 = B_SYS + system_prompt + E_SYS\n\n        instruction = \"\"\"\n        History: {history} \\n\n        User: {question}\"\"\"\n\n        prompt_template = B_INST + SYSTEM_PROMPT1 + instruction + E_INST\n        prompt = PromptTemplate(input_variables=[\"history\", \"question\"], template=prompt_template)\n\n        return prompt\n\n    def getNewChain(self, usermood):\n        prompt = self.getPromptFromTemplate()\n        memory = ConversationBufferMemory(input_key=\"question\", memory_key=\"history\", max_len=5)\n\n        # Initialize LLMChain with proper parameters\n        llm_chain = LLMChain(prompt=prompt, llm=self.llm, verbose=True, memory=memory, output_parser=CustomOutputParser())\n\n        # Return a callable that processes inputs using the chain\n        def run_chain(inputs):\n            question = inputs.get(\"question\", \"\")\n            return llm_chain.run({\"history\": \"\", \"question\": question})\n\n        return run_chain\n\nclass CustomOutputParser(StrOutputParser):\n    def parse(self, response: str):\n        return response.split('[/INST]')[-1].strip()\n\n# Load your model and tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\")\nmodel = AutoModelForCausalLM.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\", device_map={\"\": 0}, torch_dtype=torch.float16)\n\n# Load LoRA configuration and apply it to the model\nlora_config = LoraConfig.from_pretrained('/kaggle/input/fine-tuned-model2')\nmodel = get_peft_model(model, lora_config)\n\n# Initialize the StoryCreativityChain\nstory_chain = StoryCreativityChain(model, tokenizer)\n\n# Define a Chainlit message handler\n@cl.on_message\ndef handle_message(message: str):\n    chain = story_chain.getNewChain(\"Happy\")  # You can adjust `usermood` as needed\n    response = chain({\"question\": message})\n    return response\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import subprocess\n\n# Start the Chainlit app\nsubprocess.Popen(['chainlit', 'run', 'chainlit_app.py', '--port', '8080'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pyngrok import ngrok\n\n# Start ngrok\npublic_url = ngrok.connect(8080)\nprint(\"Chainlit public URL:\", public_url)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!chainlit run chainlit_app.py --port 8080","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile chainlit_app2.py\n\nimport chainlit as cl\n\n@cl.on_message\ndef handle_message(message: str):\n    return f\"You said: {message}\"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!chainlit run chainlit_app2.py --port 8080","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !killall chainlit  # Stop any running Chainlit process\nimport subprocess\nsubprocess.Popen(['chainlit', 'run', 'chainlit_app.py', '--port', '8051'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pyngrok import ngrok\n\n# Start a new ngrok tunnel\npublic_url = ngrok.connect(8080)\nprint(\"Ngrok public URL:\", public_url)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import requests\n\npublic_url = \"https://5cbb-34-82-155-222.ngrok-free.app\"\n\n# Change endpoint if needed\nendpoint = '/messages'  # Example endpoint, adjust as necessary\n\ntry:\n    response = requests.post(f'{public_url}{endpoint}', json={\"message\": \"Hello, Chainlit!\"})\n    print(\"Server Response:\", response.json())\nexcept requests.exceptions.RequestException as e:\n    print(\"Error:\", e)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!curl http://localhost:4040/api/tunnels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ps aux | grep chainlit","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !ngrok authtoken 2jb86JKOHKjdCaoHKnPIeqPbJJ9_6Zrx6tHZQeLacbEwNFuCQ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile chainlit_app3.py\n\nimport chainlit as cl\n\n@cl.on_message\ndef handle_message(message: str):\n    return f\"Received: {message}\"\n\nif __name__ == \"__main__\":\n    cl.run()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import subprocess\n\n# Start the minimal Chainlit app\nsubprocess.Popen(['chainlit', 'run', 'chainlit_app3.py', '--port', '8000'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pyngrok import ngrok\n\n# Start ngrok\npublic_url = ngrok.connect(8000)\nprint(\"Chainlit public URL:\", public_url)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **StreamLit**","metadata":{}},{"cell_type":"code","source":"!pip install streamlit","metadata":{"execution":{"iopub.status.busy":"2024-08-01T19:55:27.841438Z","iopub.execute_input":"2024-08-01T19:55:27.841842Z","iopub.status.idle":"2024-08-01T19:55:44.596090Z","shell.execute_reply.started":"2024-08-01T19:55:27.841802Z","shell.execute_reply":"2024-08-01T19:55:44.594842Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting streamlit\n  Downloading streamlit-1.37.0-py2.py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: altair<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (5.3.0)\nRequirement already satisfied: blinker<2,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.8.2)\nRequirement already satisfied: cachetools<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.2.4)\nRequirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.1.7)\nRequirement already satisfied: numpy<3,>=1.20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.26.4)\nRequirement already satisfied: packaging<25,>=20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (24.1)\nRequirement already satisfied: pandas<3,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.2.2)\nRequirement already satisfied: pillow<11,>=7.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (9.5.0)\nRequirement already satisfied: protobuf<6,>=3.20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.20.3)\nRequirement already satisfied: pyarrow>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (16.1.0)\nRequirement already satisfied: requests<3,>=2.27 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.32.3)\nRequirement already satisfied: rich<14,>=10.14.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (13.7.0)\nRequirement already satisfied: tenacity<9,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.2.3)\nRequirement already satisfied: toml<2,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from streamlit) (0.10.2)\nRequirement already satisfied: typing-extensions<5,>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.9.0)\nRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.1.41)\nCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit) (6.3.3)\nCollecting watchdog<5,>=2.1.5 (from streamlit)\n  Downloading watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl.metadata (37 kB)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.2)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.20.0)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (0.12.1)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (2.17.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.16.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\nDownloading streamlit-1.37.0-py2.py3-none-any.whl (8.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl (83 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\nSuccessfully installed pydeck-0.9.1 streamlit-1.37.0 watchdog-4.0.1\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install gtts","metadata":{"execution":{"iopub.status.busy":"2024-08-01T19:55:56.877652Z","iopub.execute_input":"2024-08-01T19:55:56.878677Z","iopub.status.idle":"2024-08-01T19:56:11.367991Z","shell.execute_reply.started":"2024-08-01T19:55:56.878637Z","shell.execute_reply":"2024-08-01T19:56:11.366778Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting gtts\n  Downloading gTTS-2.5.2-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: requests<3,>=2.27 in /opt/conda/lib/python3.10/site-packages (from gtts) (2.32.3)\nRequirement already satisfied: click<8.2,>=7.1 in /opt/conda/lib/python3.10/site-packages (from gtts) (8.1.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->gtts) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->gtts) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->gtts) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->gtts) (2024.7.4)\nDownloading gTTS-2.5.2-py3-none-any.whl (29 kB)\nInstalling collected packages: gtts\nSuccessfully installed gtts-2.5.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile streamlit_app_2.py\n\nimport streamlit as st\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, TFAutoModelForSequenceClassification\nfrom langchain import LLMChain, PromptTemplate, HuggingFacePipeline\nfrom langchain.memory.buffer import ConversationBufferMemory\nfrom langchain_core.output_parsers import StrOutputParser\nfrom peft import PeftModel, LoraConfig, get_peft_model\nimport torch\nfrom gtts import gTTS\nimport os\n\n# Custom CSS to style the app\nst.markdown(\"\"\"\n    <style>\n    body {\n        background-size: cover;\n    }\n    .main {\n        background: radial-gradient(circle at 10% 20%, rgb(69, 86, 102) 0%, rgb(34, 34, 34) 90%);\n        padding: 20px;\n        border-radius: 10px;\n        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);\n    }\n    .message {\n        padding: 10px;\n        border-radius: 10px;\n        margin-bottom: 10px;\n    }\n    .user {\n        background-color: #6897ab;\n    }\n    .assistant {\n        background-color: #848a86;\n        color: white;\n    }\n    </style>\n\"\"\", unsafe_allow_html=True)\n\nclass StoryCreativityChain:\n    def __init__(self, model, tokenizer):\n        self.llmPipeline = pipeline(\n            \"text-generation\",\n            model=model,\n            tokenizer=tokenizer,\n            torch_dtype=torch.float16,\n            device_map=\"auto\",\n            max_new_tokens=1000,\n            do_sample=True,\n            top_k=30,\n            num_return_sequences=1,\n            eos_token_id=tokenizer.eos_token_id\n        )\n        self.llm = HuggingFacePipeline(pipeline=self.llmPipeline, model_kwargs={'temperature': 0.7, 'max_length': 5, 'top_k': 50})\n\n    def getPromptFromTemplate(self):\n        system_prompt = \"\"\"You are a creative assistant specializing in generating detailed and imaginative stories, crafting interesting and well-structured recipes, and composing beautiful poetry. Follow these guidelines:\n\n        1. **Stories:** Create engaging, detailed, and imaginative stories with vivid descriptions, compelling characters, and cohesive plots. Always consider the user's mood when crafting the story.\n        2. **Recipes:** Generate step-by-step instructions for recipes that are easy to follow, include all necessary ingredients, and result in delicious dishes. Respond to recipe-related queries such as:\n           - \"What is the recipe of...\"\n           - \"How do I make...\"\n           - \"How can I make...\"\n           - \"I want to cook...\"\n        3. **Poetry:** Write poems that are meaningful, expressive, and emotionally resonant, taking the user's mood into account.\n\n        For any other requests, respond politely and concisely with:\n        \"I'm sorry, but I can only assist with stories, recipes, and poetry. Let's focus on those areas.\"\n\n        Additionally, do not generate or provide code in any programming language such as C++, Python, JavaScript, etc. If asked about coding or any other topics outside stories, recipes, and poetry, respond with:\n        \"I'm sorry, but I can only assist with stories, recipes, and poetry. Let's focus on those areas.\"\n\n        Remember:\n        - Stick strictly to stories, recipes, and poetry even if the user repeatedly asks questions other than these.\n        - Maintain a polite and helpful tone.\n        - Do not provide information or assistance outside the specified scope, regardless of user insistence.\n        \"\"\"\n\n\n\n        B_INST, E_INST = \"[INST]\", \"[/INST]\"\n        B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n        SYSTEM_PROMPT1 = B_SYS + system_prompt + E_SYS\n\n        instruction = \"\"\"\n        History: {history} \\n\n        User's Mood: {user's mood} \\n\n        User: {question}\"\"\"\n\n        prompt_template = B_INST + SYSTEM_PROMPT1 + instruction + E_INST\n        prompt = PromptTemplate(input_variables=[\"history\", \"question\", \"user's mood\"], template=prompt_template)\n\n        return prompt\n\n    def getNewChain(self):\n        prompt = self.getPromptFromTemplate()\n        memory = ConversationBufferMemory(input_key=\"question\", memory_key=\"history\", max_len=5)\n\n        # Initialize LLMChain with proper parameters\n        llm_chain = LLMChain(prompt=prompt, llm=self.llm, verbose=True, memory=memory, output_parser=CustomOutputParser())\n\n        # Return a callable that processes inputs using the chain\n        def run_chain(inputs):\n            question = inputs.get(\"question\", \"\")\n            mood = inputs.get(\"user's mood\", \"\")\n            return llm_chain.run({\"history\": \"\", \"question\": question, \"user's mood\": mood})\n\n        return run_chain\n\nclass CustomOutputParser(StrOutputParser):\n    def parse(self, response: str):\n        # Ensure response only contains content after the instruction end tag\n        return response.split('[/INST]')[-1].strip()\n\n# Cache the model and tokenizer to load them only once\n@st.cache_resource\ndef load_model_and_tokenizer():\n    model_id = \"NousResearch/Llama-2-7b-chat-hf\"\n    tokenizer = AutoTokenizer.from_pretrained(model_id)\n    model = AutoModelForCausalLM.from_pretrained(model_id, device_map={\"\": 0}, torch_dtype=torch.float16)\n\n    # Load LoRA configuration and apply it to the model\n    lora_config = LoraConfig.from_pretrained('/kaggle/input/fine-tuned-model2')\n    model = get_peft_model(model, lora_config)\n\n    # Load pre-trained emotion classifier\n    emotion_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n    emotion_model = TFAutoModelForSequenceClassification.from_pretrained(\"AaronMarker/emotionClassifier\", num_labels=9)\n    emotion_classifier = pipeline(\"text-classification\", model=emotion_model, tokenizer=emotion_tokenizer)\n\n    # Define the emotion mapping\n    emotions = {\n        'LABEL_0': 'Joy',\n        'LABEL_1': 'Desire',\n        'LABEL_2': 'Admiration',\n        'LABEL_3': 'Approval',\n        'LABEL_4': 'Curiosity',\n        'LABEL_5': 'Fear',\n        'LABEL_6': 'Sadness',\n        'LABEL_7': 'Anger',\n        'LABEL_8': 'Neutral'\n    }\n\n    return model, tokenizer, emotions, emotion_classifier\n\nmodel, tokenizer, emotions, emotion_classifier = load_model_and_tokenizer()\n\n# Initialize the StoryCreativityChain\nstory_chain = StoryCreativityChain(model, tokenizer)\n\n# Initialize session state if not already done\nif \"chain\" not in st.session_state:\n    st.session_state.chain = story_chain.getNewChain()\n    st.session_state.history = []\n\n# Streamlit app code\nst.title(\"Hey! How can I help you?\")\n\n# Sidebar with helper text\nst.sidebar.title(\"Creative Assistant\")\nst.sidebar.write(\"Hey, I am here to help you with amazing stories, recipes, and poetry.\")\nst.sidebar.markdown(\"**Let's get creative!**\")\nst.sidebar.header(\"Quick Tips:\")\nst.sidebar.markdown(\"\"\"\n- **For stories:** Use prompts like \"Tell me a story about a brave knight\" or \"Write a story about an adventure in space.\"\n- **For recipes:** Try asking \"Can you give me a recipe for chocolate cake?\" or \"How do I make a delicious pasta?\"\n- **For poetry:** Try prompts like \"Write a poem about love\" or \"Compose a poem about nature.\"\n- **Stay on topic:** Remember, I specialize in stories, recipes, and poetry. Let's keep our chat focused on these!\n\"\"\")\n\n# User input\nuser_input = st.text_input(\"Enter your prompt:\")\n\n# Function to predict emotion\ndef predict_emotion(sentence):\n    prediction = emotions[emotion_classifier(sentence)[0][\"label\"]]\n    return prediction\n\n# Function to convert text to audio\ndef text_to_audio(text, filename=\"response.mp3\"):\n    tts = gTTS(text)\n    tts.save(filename)\n    return filename\n\nif st.button(\"Generate Response\"):\n    if user_input:\n        # Add user message to history\n        st.session_state.history.append({\"role\": \"user\", \"content\": user_input})\n        \n        # Generate response\n        response = st.session_state.chain({\"question\": user_input, \"user's mood\": predict_emotion(user_input)})\n        \n        # Convert response to audio\n        audio_file = text_to_audio(response)\n        \n        # Add assistant response to history\n        st.session_state.history.append({\"role\": \"assistant\", \"content\": response})\n        \n        # Display audio player\n        st.audio(audio_file)\n\n    else:\n        st.write(\"Please enter a prompt.\")\n\n# Display chat history\nst.write('<div class=\"main\">', unsafe_allow_html=True)\nfor message in st.session_state.history:\n    role_class = \"user\" if message[\"role\"] == \"user\" else \"assistant\"\n    st.write(f'<div class=\"message {role_class}\">{message[\"content\"]}</div>', unsafe_allow_html=True)\nst.write('</div>', unsafe_allow_html=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-01T19:56:21.437117Z","iopub.execute_input":"2024-08-01T19:56:21.437480Z","iopub.status.idle":"2024-08-01T19:56:21.449899Z","shell.execute_reply.started":"2024-08-01T19:56:21.437452Z","shell.execute_reply":"2024-08-01T19:56:21.448791Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Overwriting streamlit_app_2.py\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_id = \"NousResearch/Llama-2-7b-chat-hf\"\n# bnb_config = BitsAndBytesConfig(\n#     load_in_4bit=True,\n#     bnb_4bit_use_double_quant=True,\n#     bnb_4bit_quant_type=\"nf4\",\n#     bnb_4bit_compute_dtype=torch.bfloat16\n# )\n\n# tokenizer = AutoTokenizer.from_pretrained(model_id)\n# model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pyngrok","metadata":{"execution":{"iopub.status.busy":"2024-08-01T19:56:31.474218Z","iopub.execute_input":"2024-08-01T19:56:31.474880Z","iopub.status.idle":"2024-08-01T19:56:45.849180Z","shell.execute_reply.started":"2024-08-01T19:56:31.474849Z","shell.execute_reply":"2024-08-01T19:56:45.847906Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting pyngrok\n  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from pyngrok) (6.0.1)\nDownloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\nInstalling collected packages: pyngrok\nSuccessfully installed pyngrok-7.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from pyngrok import ngrok\n\n# Start a new ngrok tunnel\npublic_url = ngrok.connect(8000)\nprint(\"Ngrok public URL:\", public_url)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T19:57:02.324241Z","iopub.execute_input":"2024-08-01T19:57:02.324673Z","iopub.status.idle":"2024-08-01T19:57:02.668360Z","shell.execute_reply.started":"2024-08-01T19:57:02.324636Z","shell.execute_reply":"2024-08-01T19:57:02.667260Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Ngrok public URL: NgrokTunnel: \"https://cfb1-34-135-156-149.ngrok-free.app\" -> \"http://localhost:8000\"\n","output_type":"stream"}]},{"cell_type":"code","source":"!streamlit run streamlit_app_2.py --server.port 8000","metadata":{"execution":{"iopub.status.busy":"2024-08-01T19:57:06.533088Z","iopub.execute_input":"2024-08-01T19:57:06.533452Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"\nCollecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n\u001b[0m\n\u001b[0m\n\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n\u001b[0m\n\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8000\u001b[0m\n\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.19.2.2:8000\u001b[0m\n\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.135.156.149:8000\u001b[0m\n\u001b[0m\n2024-08-01 19:57:26.636025: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-01 19:57:26.636200: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-01 19:57:26.771754: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/langchain/__init__.py:30: UserWarning: Importing LLMChain from langchain root module is no longer supported. Please use langchain.chains.LLMChain instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/langchain/__init__.py:30: UserWarning: Importing PromptTemplate from langchain root module is no longer supported. Please use langchain_core.prompts.PromptTemplate instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/langchain/__init__.py:30: UserWarning: Importing HuggingFacePipeline from langchain root module is no longer supported. Please use langchain_community.llms.huggingface_pipeline.HuggingFacePipeline instead.\n  warnings.warn(\ntokenizer_config.json: 100%|███████████████████| 746/746 [00:00<00:00, 3.10MB/s]\ntokenizer.model: 100%|███████████████████████| 500k/500k [00:00<00:00, 9.69MB/s]\ntokenizer.json: 100%|██████████████████████| 1.84M/1.84M [00:00<00:00, 20.2MB/s]\nadded_tokens.json: 100%|██████████████████████| 21.0/21.0 [00:00<00:00, 107kB/s]\nspecial_tokens_map.json: 100%|█████████████████| 435/435 [00:00<00:00, 2.29MB/s]\nconfig.json: 100%|█████████████████████████████| 583/583 [00:00<00:00, 2.73MB/s]\nmodel.safetensors.index.json: 100%|████████| 26.8k/26.8k [00:00<00:00, 78.6MB/s]\nDownloading shards:   0%|                                 | 0/2 [00:00<?, ?it/s]\nmodel-00001-of-00002.safetensors:   0%|             | 0.00/9.98G [00:00<?, ?B/s]\u001b[A\nmodel-00001-of-00002.safetensors:   0%|     | 21.0M/9.98G [00:00<01:02, 158MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   0%|     | 41.9M/9.98G [00:00<00:55, 178MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   1%|     | 62.9M/9.98G [00:00<00:52, 190MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   1%|     | 83.9M/9.98G [00:00<00:50, 197MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   1%|      | 105M/9.98G [00:00<00:49, 198MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   1%|      | 136M/9.98G [00:00<00:47, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   2%|      | 157M/9.98G [00:00<00:47, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   2%|      | 178M/9.98G [00:00<00:48, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   2%|      | 199M/9.98G [00:01<00:48, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   2%|▏     | 220M/9.98G [00:01<00:48, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   3%|▏     | 252M/9.98G [00:01<00:47, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   3%|▏     | 283M/9.98G [00:01<00:46, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   3%|▏     | 304M/9.98G [00:01<00:46, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   3%|▏     | 325M/9.98G [00:01<00:46, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   4%|▏     | 357M/9.98G [00:01<00:46, 208MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   4%|▏     | 377M/9.98G [00:01<00:46, 208MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   4%|▏     | 398M/9.98G [00:01<00:46, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   4%|▎     | 419M/9.98G [00:02<00:46, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   4%|▎     | 440M/9.98G [00:02<00:47, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   5%|▎     | 461M/9.98G [00:02<00:46, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   5%|▎     | 482M/9.98G [00:02<00:46, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   5%|▎     | 503M/9.98G [00:02<00:46, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   5%|▎     | 524M/9.98G [00:02<00:46, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   5%|▎     | 545M/9.98G [00:02<00:46, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   6%|▎     | 577M/9.98G [00:02<00:45, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   6%|▎     | 608M/9.98G [00:02<00:44, 208MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   6%|▍     | 640M/9.98G [00:03<00:44, 208MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   7%|▍     | 661M/9.98G [00:03<00:44, 208MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   7%|▍     | 682M/9.98G [00:03<00:44, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   7%|▍     | 713M/9.98G [00:03<00:44, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   7%|▍     | 734M/9.98G [00:03<00:44, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   8%|▍     | 755M/9.98G [00:03<00:44, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   8%|▍     | 776M/9.98G [00:03<00:45, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   8%|▍     | 797M/9.98G [00:03<00:44, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   8%|▍     | 818M/9.98G [00:04<00:45, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   8%|▌     | 839M/9.98G [00:04<00:44, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   9%|▌     | 860M/9.98G [00:04<00:44, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   9%|▌     | 881M/9.98G [00:04<00:44, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   9%|▌     | 912M/9.98G [00:04<00:43, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   9%|▌     | 933M/9.98G [00:04<00:43, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  10%|▌     | 954M/9.98G [00:04<00:43, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  10%|▌     | 975M/9.98G [00:04<00:43, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  10%|▌     | 996M/9.98G [00:04<00:43, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  10%|▌    | 1.02G/9.98G [00:04<00:43, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  10%|▌    | 1.04G/9.98G [00:05<00:43, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  11%|▌    | 1.06G/9.98G [00:05<00:43, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  11%|▌    | 1.08G/9.98G [00:05<00:43, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  11%|▌    | 1.10G/9.98G [00:05<00:42, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  11%|▌    | 1.12G/9.98G [00:05<00:42, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  11%|▌    | 1.14G/9.98G [00:05<00:42, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  12%|▌    | 1.16G/9.98G [00:05<00:42, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  12%|▌    | 1.18G/9.98G [00:05<00:42, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  12%|▌    | 1.21G/9.98G [00:05<00:42, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  12%|▌    | 1.23G/9.98G [00:05<00:42, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  13%|▋    | 1.25G/9.98G [00:06<00:42, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  13%|▋    | 1.27G/9.98G [00:06<00:42, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  13%|▋    | 1.29G/9.98G [00:06<00:42, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  13%|▋    | 1.31G/9.98G [00:06<00:43, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  13%|▋    | 1.33G/9.98G [00:06<00:42, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  14%|▋    | 1.35G/9.98G [00:06<00:42, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  14%|▋    | 1.37G/9.98G [00:06<00:43, 200MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  14%|▋    | 1.39G/9.98G [00:06<00:43, 199MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  14%|▋    | 1.42G/9.98G [00:06<00:42, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  14%|▋    | 1.44G/9.98G [00:07<00:42, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  15%|▋    | 1.46G/9.98G [00:07<00:42, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  15%|▋    | 1.48G/9.98G [00:07<00:42, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  15%|▊    | 1.50G/9.98G [00:07<00:41, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  15%|▊    | 1.52G/9.98G [00:07<00:41, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  15%|▊    | 1.54G/9.98G [00:07<00:41, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  16%|▊    | 1.56G/9.98G [00:07<00:41, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  16%|▊    | 1.58G/9.98G [00:07<00:41, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  16%|▊    | 1.61G/9.98G [00:07<00:40, 208MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  17%|▊    | 1.65G/9.98G [00:08<00:39, 210MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  17%|▊    | 1.67G/9.98G [00:08<00:40, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  17%|▊    | 1.69G/9.98G [00:08<00:40, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  17%|▊    | 1.71G/9.98G [00:08<00:40, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  17%|▊    | 1.73G/9.98G [00:08<00:40, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  18%|▉    | 1.75G/9.98G [00:08<00:40, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  18%|▉    | 1.77G/9.98G [00:08<00:40, 200MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  18%|▉    | 1.79G/9.98G [00:08<00:40, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  18%|▉    | 1.81G/9.98G [00:08<00:40, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  18%|▉    | 1.84G/9.98G [00:08<00:40, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  19%|▉    | 1.86G/9.98G [00:09<00:40, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  19%|▉    | 1.88G/9.98G [00:09<00:39, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  19%|▉    | 1.90G/9.98G [00:09<00:39, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  19%|▉    | 1.93G/9.98G [00:09<00:39, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  20%|▉    | 1.95G/9.98G [00:09<00:38, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  20%|▉    | 1.97G/9.98G [00:09<00:38, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  20%|▉    | 1.99G/9.98G [00:09<00:38, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  20%|█    | 2.01G/9.98G [00:09<00:38, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  20%|█    | 2.03G/9.98G [00:09<00:38, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  21%|█    | 2.06G/9.98G [00:10<00:38, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  21%|█    | 2.08G/9.98G [00:10<00:38, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  21%|█    | 2.10G/9.98G [00:10<00:38, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  21%|█    | 2.12G/9.98G [00:10<00:38, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  21%|█    | 2.14G/9.98G [00:10<00:40, 195MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  22%|█    | 2.16G/9.98G [00:10<00:43, 181MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  22%|█    | 2.18G/9.98G [00:10<00:41, 188MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  22%|█    | 2.20G/9.98G [00:10<00:40, 193MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  22%|█    | 2.22G/9.98G [00:11<01:04, 121MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  22%|█    | 2.24G/9.98G [00:11<00:56, 138MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  23%|█▏   | 2.26G/9.98G [00:11<00:50, 152MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  23%|█▏   | 2.29G/9.98G [00:11<00:46, 166MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  23%|█▏   | 2.31G/9.98G [00:11<00:43, 177MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  23%|█▏   | 2.33G/9.98G [00:11<00:41, 185MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  24%|█▏   | 2.35G/9.98G [00:11<00:39, 191MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  24%|█▏   | 2.37G/9.98G [00:11<00:39, 193MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  24%|█▏   | 2.39G/9.98G [00:11<00:38, 195MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  24%|█▏   | 2.41G/9.98G [00:12<00:38, 197MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  24%|█▏   | 2.43G/9.98G [00:12<00:37, 200MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  25%|█▏   | 2.45G/9.98G [00:12<00:37, 199MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  25%|█▏   | 2.47G/9.98G [00:12<00:37, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  25%|█▎   | 2.50G/9.98G [00:12<00:36, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  25%|█▎   | 2.52G/9.98G [00:12<00:37, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  25%|█▎   | 2.54G/9.98G [00:12<00:37, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  26%|█▎   | 2.56G/9.98G [00:12<00:36, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  26%|█▎   | 2.58G/9.98G [00:12<00:36, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  26%|█▎   | 2.61G/9.98G [00:13<00:35, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  26%|█▎   | 2.63G/9.98G [00:13<00:36, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  27%|█▎   | 2.65G/9.98G [00:13<00:35, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  27%|█▎   | 2.67G/9.98G [00:13<00:35, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  27%|█▎   | 2.69G/9.98G [00:13<00:35, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  27%|█▎   | 2.72G/9.98G [00:13<00:35, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  27%|█▎   | 2.74G/9.98G [00:13<00:35, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  28%|█▍   | 2.76G/9.98G [00:13<00:35, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  28%|█▍   | 2.79G/9.98G [00:13<00:34, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  28%|█▍   | 2.81G/9.98G [00:14<00:34, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  28%|█▍   | 2.83G/9.98G [00:14<00:34, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  29%|█▍   | 2.85G/9.98G [00:14<00:34, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  29%|█▍   | 2.87G/9.98G [00:14<00:34, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  29%|█▍   | 2.89G/9.98G [00:14<00:34, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  29%|█▍   | 2.92G/9.98G [00:14<00:34, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  29%|█▍   | 2.94G/9.98G [00:14<00:34, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  30%|█▍   | 2.96G/9.98G [00:14<00:34, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  30%|█▍   | 2.98G/9.98G [00:14<00:34, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  30%|█▌   | 3.00G/9.98G [00:14<00:34, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  30%|█▌   | 3.02G/9.98G [00:15<00:34, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  30%|█▌   | 3.04G/9.98G [00:15<00:33, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  31%|█▌   | 3.06G/9.98G [00:15<00:33, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  31%|█▌   | 3.08G/9.98G [00:15<00:33, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  31%|█▌   | 3.10G/9.98G [00:15<00:33, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  31%|█▌   | 3.12G/9.98G [00:15<00:33, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  32%|█▌   | 3.15G/9.98G [00:15<00:33, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  32%|█▌   | 3.17G/9.98G [00:15<00:33, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  32%|█▌   | 3.19G/9.98G [00:15<00:33, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  32%|█▌   | 3.21G/9.98G [00:15<00:33, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  32%|█▌   | 3.23G/9.98G [00:16<00:33, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  33%|█▋   | 3.25G/9.98G [00:16<00:33, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  33%|█▋   | 3.27G/9.98G [00:16<00:33, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  33%|█▋   | 3.29G/9.98G [00:16<00:33, 200MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  33%|█▋   | 3.31G/9.98G [00:16<00:33, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  33%|█▋   | 3.33G/9.98G [00:16<00:33, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  34%|█▋   | 3.36G/9.98G [00:16<00:32, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  34%|█▋   | 3.38G/9.98G [00:16<00:32, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  34%|█▋   | 3.40G/9.98G [00:16<00:31, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  34%|█▋   | 3.42G/9.98G [00:16<00:31, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  35%|█▋   | 3.45G/9.98G [00:17<00:31, 209MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  35%|█▋   | 3.47G/9.98G [00:17<00:31, 208MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  35%|█▊   | 3.50G/9.98G [00:17<00:30, 209MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  35%|█▊   | 3.52G/9.98G [00:17<00:30, 209MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  36%|█▊   | 3.54G/9.98G [00:17<00:31, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  36%|█▊   | 3.58G/9.98G [00:17<00:30, 208MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  36%|█▊   | 3.61G/9.98G [00:17<00:30, 209MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  36%|█▊   | 3.63G/9.98G [00:18<00:30, 208MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  37%|█▊   | 3.65G/9.98G [00:18<00:30, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  37%|█▊   | 3.67G/9.98G [00:18<00:30, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  37%|█▊   | 3.69G/9.98G [00:18<00:30, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  37%|█▊   | 3.71G/9.98G [00:18<00:30, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  37%|█▊   | 3.73G/9.98G [00:18<00:30, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  38%|█▉   | 3.75G/9.98G [00:18<00:30, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  38%|█▉   | 3.77G/9.98G [00:18<00:30, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  38%|█▉   | 3.80G/9.98G [00:18<00:30, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  38%|█▉   | 3.82G/9.98G [00:18<00:30, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  38%|█▉   | 3.84G/9.98G [00:19<00:30, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  39%|█▉   | 3.86G/9.98G [00:19<00:30, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  39%|█▉   | 3.88G/9.98G [00:19<00:29, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  39%|█▉   | 3.90G/9.98G [00:19<00:29, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  39%|█▉   | 3.92G/9.98G [00:19<00:29, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  40%|█▉   | 3.94G/9.98G [00:19<00:29, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  40%|█▉   | 3.96G/9.98G [00:19<00:29, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  40%|██   | 4.00G/9.98G [00:19<00:28, 208MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  40%|██   | 4.02G/9.98G [00:19<00:28, 208MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  40%|██   | 4.04G/9.98G [00:20<00:28, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  41%|██   | 4.07G/9.98G [00:20<00:28, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  41%|██   | 4.10G/9.98G [00:20<00:28, 208MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  41%|██   | 4.12G/9.98G [00:20<00:28, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  42%|██   | 4.14G/9.98G [00:20<00:28, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  42%|██   | 4.17G/9.98G [00:20<00:28, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  42%|██   | 4.19G/9.98G [00:20<00:33, 174MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  42%|██   | 4.23G/9.98G [00:20<00:30, 186MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  43%|██▏  | 4.26G/9.98G [00:21<00:29, 192MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  43%|██▏  | 4.29G/9.98G [00:21<00:28, 198MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  43%|██▏  | 4.31G/9.98G [00:21<00:28, 200MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  43%|██▏  | 4.33G/9.98G [00:21<00:27, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  44%|██▏  | 4.35G/9.98G [00:21<00:27, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  44%|██▏  | 4.37G/9.98G [00:21<00:27, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  44%|██▏  | 4.40G/9.98G [00:21<00:27, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  44%|██▏  | 4.42G/9.98G [00:21<00:26, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  45%|██▏  | 4.46G/9.98G [00:22<00:26, 208MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  45%|██▏  | 4.49G/9.98G [00:22<00:26, 209MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  45%|██▎  | 4.52G/9.98G [00:22<00:26, 209MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  46%|██▎  | 4.54G/9.98G [00:22<00:26, 208MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  46%|██▎  | 4.56G/9.98G [00:22<00:26, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  46%|██▎  | 4.58G/9.98G [00:22<00:26, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  46%|██▎  | 4.60G/9.98G [00:22<00:26, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  46%|██▎  | 4.62G/9.98G [00:22<00:26, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  47%|██▎  | 4.65G/9.98G [00:23<00:26, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  47%|██▎  | 4.67G/9.98G [00:23<00:26, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  47%|██▎  | 4.69G/9.98G [00:23<00:25, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  47%|██▎  | 4.71G/9.98G [00:23<00:25, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  47%|██▎  | 4.73G/9.98G [00:23<00:25, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  48%|██▍  | 4.75G/9.98G [00:23<00:25, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  48%|██▍  | 4.77G/9.98G [00:23<00:25, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  48%|██▍  | 4.79G/9.98G [00:23<00:25, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  48%|██▍  | 4.81G/9.98G [00:23<00:25, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  48%|██▍  | 4.83G/9.98G [00:23<00:25, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  49%|██▍  | 4.85G/9.98G [00:24<00:25, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  49%|██▍  | 4.88G/9.98G [00:24<00:25, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  49%|██▍  | 4.90G/9.98G [00:24<00:24, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  49%|██▍  | 4.92G/9.98G [00:24<00:24, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  50%|██▍  | 4.95G/9.98G [00:24<00:24, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  50%|██▍  | 4.97G/9.98G [00:24<00:24, 208MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  50%|██▌  | 4.99G/9.98G [00:24<00:24, 208MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  50%|██▌  | 5.01G/9.98G [00:24<00:24, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  50%|██▌  | 5.03G/9.98G [00:24<00:23, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  51%|██▌  | 5.05G/9.98G [00:24<00:23, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  51%|██▌  | 5.08G/9.98G [00:25<00:23, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  51%|██▌  | 5.10G/9.98G [00:25<00:23, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  51%|██▌  | 5.12G/9.98G [00:25<00:23, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  52%|██▌  | 5.14G/9.98G [00:25<00:23, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  52%|██▌  | 5.16G/9.98G [00:25<00:23, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  52%|██▌  | 5.18G/9.98G [00:25<00:23, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  52%|██▌  | 5.20G/9.98G [00:25<00:22, 208MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  52%|██▌  | 5.22G/9.98G [00:25<00:22, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  53%|██▋  | 5.24G/9.98G [00:25<00:22, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  53%|██▋  | 5.26G/9.98G [00:26<00:22, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  53%|██▋  | 5.28G/9.98G [00:26<00:22, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  53%|██▋  | 5.31G/9.98G [00:26<00:22, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  53%|██▋  | 5.33G/9.98G [00:26<00:22, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  54%|██▋  | 5.35G/9.98G [00:26<00:22, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  54%|██▋  | 5.37G/9.98G [00:26<00:22, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  54%|██▋  | 5.39G/9.98G [00:26<00:22, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  54%|██▋  | 5.41G/9.98G [00:26<00:22, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  54%|██▋  | 5.43G/9.98G [00:26<00:22, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  55%|██▋  | 5.46G/9.98G [00:26<00:21, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  55%|██▋  | 5.48G/9.98G [00:27<00:21, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  55%|██▊  | 5.51G/9.98G [00:27<00:21, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  55%|██▊  | 5.53G/9.98G [00:27<00:21, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  56%|██▊  | 5.55G/9.98G [00:27<00:21, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  56%|██▊  | 5.57G/9.98G [00:27<00:21, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  56%|██▊  | 5.59G/9.98G [00:27<00:21, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  56%|██▊  | 5.61G/9.98G [00:27<00:21, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  56%|██▊  | 5.63G/9.98G [00:27<00:21, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  57%|██▊  | 5.65G/9.98G [00:27<00:21, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  57%|██▊  | 5.67G/9.98G [00:28<00:21, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  57%|██▊  | 5.69G/9.98G [00:28<00:20, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  57%|██▊  | 5.71G/9.98G [00:28<00:21, 200MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  57%|██▊  | 5.74G/9.98G [00:28<00:21, 200MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  58%|██▉  | 5.76G/9.98G [00:28<00:20, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  58%|██▉  | 5.78G/9.98G [00:28<00:20, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  58%|██▉  | 5.80G/9.98G [00:28<00:20, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  58%|██▉  | 5.82G/9.98G [00:28<00:20, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  59%|██▉  | 5.84G/9.98G [00:28<00:20, 199MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  59%|██▉  | 5.86G/9.98G [00:28<00:21, 191MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  59%|██▉  | 5.88G/9.98G [00:29<00:21, 194MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  59%|██▉  | 5.90G/9.98G [00:29<00:20, 196MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  59%|██▉  | 5.92G/9.98G [00:29<00:20, 197MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  60%|██▉  | 5.95G/9.98G [00:29<00:20, 198MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  60%|██▉  | 5.97G/9.98G [00:29<00:20, 200MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  60%|███  | 5.99G/9.98G [00:29<00:19, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  60%|███  | 6.01G/9.98G [00:29<00:19, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  60%|███  | 6.03G/9.98G [00:30<00:31, 126MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  61%|███  | 6.05G/9.98G [00:30<00:27, 142MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  61%|███  | 6.07G/9.98G [00:30<00:24, 157MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  61%|███  | 6.09G/9.98G [00:30<00:22, 169MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  61%|███  | 6.12G/9.98G [00:30<00:21, 182MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  62%|███  | 6.14G/9.98G [00:30<00:20, 188MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  62%|███  | 6.17G/9.98G [00:30<00:19, 192MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  62%|███  | 6.19G/9.98G [00:30<00:19, 196MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  62%|███  | 6.21G/9.98G [00:30<00:18, 199MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  62%|███  | 6.23G/9.98G [00:31<00:20, 183MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  63%|███▏ | 6.26G/9.98G [00:31<00:19, 193MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  63%|███▏ | 6.28G/9.98G [00:31<00:18, 197MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  63%|███▏ | 6.30G/9.98G [00:31<00:18, 199MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  63%|███▏ | 6.32G/9.98G [00:31<00:18, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  64%|███▏ | 6.34G/9.98G [00:31<00:17, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  64%|███▏ | 6.36G/9.98G [00:31<00:17, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  64%|███▏ | 6.39G/9.98G [00:31<00:17, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  64%|███▏ | 6.41G/9.98G [00:31<00:17, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  64%|███▏ | 6.43G/9.98G [00:31<00:17, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  65%|███▏ | 6.45G/9.98G [00:32<00:17, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  65%|███▏ | 6.47G/9.98G [00:32<00:17, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  65%|███▎ | 6.49G/9.98G [00:32<00:17, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  65%|███▎ | 6.51G/9.98G [00:32<00:17, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  65%|███▎ | 6.53G/9.98G [00:32<00:16, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  66%|███▎ | 6.56G/9.98G [00:32<00:16, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  66%|███▎ | 6.59G/9.98G [00:32<00:16, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  66%|███▎ | 6.62G/9.98G [00:32<00:16, 208MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  67%|███▎ | 6.64G/9.98G [00:32<00:16, 208MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  67%|███▎ | 6.66G/9.98G [00:33<00:16, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  67%|███▎ | 6.68G/9.98G [00:33<00:15, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  67%|███▎ | 6.70G/9.98G [00:33<00:15, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  67%|███▎ | 6.72G/9.98G [00:33<00:15, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  68%|███▍ | 6.74G/9.98G [00:33<00:15, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  68%|███▍ | 6.76G/9.98G [00:33<00:15, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  68%|███▍ | 6.78G/9.98G [00:33<00:15, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  68%|███▍ | 6.81G/9.98G [00:33<00:15, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  68%|███▍ | 6.83G/9.98G [00:33<00:15, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  69%|███▍ | 6.85G/9.98G [00:34<00:15, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  69%|███▍ | 6.87G/9.98G [00:34<00:15, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  69%|███▍ | 6.89G/9.98G [00:34<00:15, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  69%|███▍ | 6.91G/9.98G [00:34<00:14, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  69%|███▍ | 6.93G/9.98G [00:34<00:14, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  70%|███▍ | 6.96G/9.98G [00:34<00:14, 209MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  70%|███▍ | 6.98G/9.98G [00:34<00:14, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  70%|███▌ | 7.00G/9.98G [00:34<00:14, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  70%|███▌ | 7.03G/9.98G [00:34<00:14, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  71%|███▌ | 7.05G/9.98G [00:34<00:14, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  71%|███▌ | 7.07G/9.98G [00:35<00:14, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  71%|███▌ | 7.09G/9.98G [00:35<00:14, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  71%|███▌ | 7.12G/9.98G [00:35<00:13, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  72%|███▌ | 7.14G/9.98G [00:35<00:13, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  72%|███▌ | 7.16G/9.98G [00:35<00:13, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  72%|███▌ | 7.18G/9.98G [00:35<00:13, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  72%|███▌ | 7.20G/9.98G [00:35<00:13, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  72%|███▌ | 7.22G/9.98G [00:35<00:13, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  73%|███▋ | 7.25G/9.98G [00:35<00:13, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  73%|███▋ | 7.27G/9.98G [00:36<00:13, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  73%|███▋ | 7.29G/9.98G [00:36<00:13, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  73%|███▋ | 7.31G/9.98G [00:36<00:13, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  73%|███▋ | 7.33G/9.98G [00:36<00:13, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  74%|███▋ | 7.35G/9.98G [00:36<00:12, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  74%|███▋ | 7.37G/9.98G [00:36<00:12, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  74%|███▋ | 7.39G/9.98G [00:36<00:12, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  74%|███▋ | 7.41G/9.98G [00:36<00:12, 200MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  75%|███▋ | 7.43G/9.98G [00:36<00:12, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  75%|███▋ | 7.46G/9.98G [00:37<00:12, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  75%|███▋ | 7.48G/9.98G [00:37<00:12, 200MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  75%|███▊ | 7.50G/9.98G [00:37<00:12, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  75%|███▊ | 7.52G/9.98G [00:37<00:12, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  76%|███▊ | 7.54G/9.98G [00:37<00:12, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  76%|███▊ | 7.56G/9.98G [00:37<00:12, 199MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  76%|███▊ | 7.58G/9.98G [00:37<00:11, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  76%|███▊ | 7.60G/9.98G [00:37<00:11, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  76%|███▊ | 7.62G/9.98G [00:37<00:11, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  77%|███▊ | 7.64G/9.98G [00:37<00:11, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  77%|███▊ | 7.67G/9.98G [00:38<00:11, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  77%|███▊ | 7.69G/9.98G [00:38<00:11, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  77%|███▊ | 7.71G/9.98G [00:38<00:10, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  77%|███▊ | 7.73G/9.98G [00:38<00:11, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  78%|███▉ | 7.75G/9.98G [00:38<00:11, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  78%|███▉ | 7.77G/9.98G [00:38<00:10, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  78%|███▉ | 7.79G/9.98G [00:38<00:10, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  78%|███▉ | 7.81G/9.98G [00:38<00:10, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  79%|███▉ | 7.83G/9.98G [00:38<00:10, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  79%|███▉ | 7.85G/9.98G [00:38<00:10, 200MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  79%|███▉ | 7.87G/9.98G [00:39<00:10, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  79%|███▉ | 7.90G/9.98G [00:39<00:10, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  79%|███▉ | 7.92G/9.98G [00:39<00:10, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  80%|███▉ | 7.94G/9.98G [00:39<00:09, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  80%|███▉ | 7.96G/9.98G [00:39<00:09, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  80%|████ | 7.99G/9.98G [00:39<00:09, 208MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  80%|████ | 8.01G/9.98G [00:39<00:09, 209MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  81%|████ | 8.04G/9.98G [00:39<00:09, 209MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  81%|████ | 8.06G/9.98G [00:39<00:09, 208MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  81%|████ | 8.08G/9.98G [00:40<00:09, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  81%|████ | 8.11G/9.98G [00:40<00:09, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  81%|████ | 8.13G/9.98G [00:40<00:09, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  82%|████ | 8.15G/9.98G [00:40<00:09, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  82%|████ | 8.17G/9.98G [00:40<00:08, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  82%|████ | 8.19G/9.98G [00:40<00:08, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  82%|████ | 8.21G/9.98G [00:40<00:08, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  83%|████▏| 8.23G/9.98G [00:40<00:08, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  83%|████▏| 8.25G/9.98G [00:40<00:08, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  83%|████▏| 8.27G/9.98G [00:41<00:08, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  83%|████▏| 8.29G/9.98G [00:41<00:08, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  83%|████▏| 8.32G/9.98G [00:41<00:09, 170MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  84%|████▏| 8.34G/9.98G [00:41<00:09, 178MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  84%|████▏| 8.36G/9.98G [00:41<00:08, 183MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  84%|████▏| 8.38G/9.98G [00:41<00:08, 187MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  84%|████▏| 8.40G/9.98G [00:41<00:08, 190MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  84%|████▏| 8.42G/9.98G [00:41<00:08, 190MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  85%|████▏| 8.44G/9.98G [00:41<00:07, 192MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  85%|████▏| 8.46G/9.98G [00:42<00:07, 196MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  85%|████▎| 8.48G/9.98G [00:42<00:07, 197MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  85%|████▎| 8.50G/9.98G [00:42<00:07, 199MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  85%|████▎| 8.52G/9.98G [00:42<00:07, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  86%|████▎| 8.55G/9.98G [00:42<00:07, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  86%|████▎| 8.57G/9.98G [00:42<00:06, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  86%|████▎| 8.59G/9.98G [00:42<00:06, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  86%|████▎| 8.62G/9.98G [00:42<00:06, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  87%|████▎| 8.64G/9.98G [00:42<00:06, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  87%|████▎| 8.66G/9.98G [00:42<00:06, 208MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  87%|████▎| 8.68G/9.98G [00:43<00:06, 208MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  87%|████▎| 8.70G/9.98G [00:43<00:06, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  87%|████▎| 8.72G/9.98G [00:43<00:06, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  88%|████▍| 8.75G/9.98G [00:43<00:06, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  88%|████▍| 8.77G/9.98G [00:43<00:05, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  88%|████▍| 8.79G/9.98G [00:43<00:05, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  88%|████▍| 8.82G/9.98G [00:43<00:05, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  89%|████▍| 8.85G/9.98G [00:43<00:05, 208MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  89%|████▍| 8.87G/9.98G [00:44<00:05, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  89%|████▍| 8.89G/9.98G [00:44<00:05, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  89%|████▍| 8.91G/9.98G [00:44<00:05, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  90%|████▍| 8.93G/9.98G [00:44<00:05, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  90%|████▍| 8.95G/9.98G [00:44<00:05, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  90%|████▍| 8.98G/9.98G [00:44<00:04, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  90%|████▌| 9.00G/9.98G [00:44<00:04, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  90%|████▌| 9.02G/9.98G [00:44<00:04, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  91%|████▌| 9.04G/9.98G [00:44<00:04, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  91%|████▌| 9.06G/9.98G [00:44<00:04, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  91%|████▌| 9.08G/9.98G [00:45<00:04, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  91%|████▌| 9.10G/9.98G [00:45<00:04, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  91%|████▌| 9.12G/9.98G [00:45<00:04, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  92%|████▌| 9.14G/9.98G [00:45<00:04, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  92%|████▌| 9.16G/9.98G [00:45<00:04, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  92%|████▌| 9.19G/9.98G [00:45<00:03, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  92%|████▌| 9.21G/9.98G [00:45<00:03, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  92%|████▌| 9.23G/9.98G [00:45<00:03, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  93%|████▋| 9.25G/9.98G [00:45<00:03, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  93%|████▋| 9.27G/9.98G [00:45<00:03, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  93%|████▋| 9.29G/9.98G [00:46<00:03, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  93%|████▋| 9.31G/9.98G [00:46<00:03, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  94%|████▋| 9.33G/9.98G [00:46<00:03, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  94%|████▋| 9.35G/9.98G [00:46<00:03, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  94%|████▋| 9.37G/9.98G [00:46<00:02, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  94%|████▋| 9.40G/9.98G [00:46<00:02, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  94%|████▋| 9.42G/9.98G [00:46<00:02, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  95%|████▋| 9.44G/9.98G [00:46<00:02, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  95%|████▋| 9.46G/9.98G [00:46<00:02, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  95%|████▊| 9.48G/9.98G [00:47<00:02, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  95%|████▊| 9.50G/9.98G [00:47<00:02, 200MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  95%|████▊| 9.52G/9.98G [00:47<00:02, 201MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  96%|████▊| 9.54G/9.98G [00:47<00:02, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  96%|████▊| 9.56G/9.98G [00:47<00:02, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  96%|████▊| 9.58G/9.98G [00:47<00:01, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  96%|████▊| 9.60G/9.98G [00:47<00:01, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  96%|████▊| 9.63G/9.98G [00:47<00:01, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  97%|████▊| 9.65G/9.98G [00:47<00:01, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  97%|████▊| 9.67G/9.98G [00:47<00:01, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  97%|████▊| 9.69G/9.98G [00:48<00:01, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  97%|████▊| 9.71G/9.98G [00:48<00:01, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  98%|████▉| 9.73G/9.98G [00:48<00:01, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  98%|████▉| 9.76G/9.98G [00:48<00:01, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  98%|████▉| 9.78G/9.98G [00:48<00:00, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  98%|████▉| 9.80G/9.98G [00:48<00:00, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  98%|████▉| 9.83G/9.98G [00:48<00:00, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  99%|████▉| 9.85G/9.98G [00:48<00:00, 206MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  99%|████▉| 9.87G/9.98G [00:48<00:00, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  99%|████▉| 9.89G/9.98G [00:49<00:00, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  99%|████▉| 9.91G/9.98G [00:49<00:00, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors: 100%|████▉| 9.93G/9.98G [00:49<00:00, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors: 100%|████▉| 9.95G/9.98G [00:49<00:00, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors: 100%|█████| 9.98G/9.98G [00:49<00:00, 202MB/s]\u001b[A\nDownloading shards:  50%|████████████▌            | 1/2 [00:49<00:49, 49.56s/it]\nmodel-00002-of-00002.safetensors:   0%|             | 0.00/3.50G [00:00<?, ?B/s]\u001b[A\nmodel-00002-of-00002.safetensors:   1%|     | 21.0M/3.50G [00:00<00:17, 198MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   1%|     | 41.9M/3.50G [00:00<00:17, 201MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   2%|     | 62.9M/3.50G [00:00<00:16, 203MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   2%|     | 83.9M/3.50G [00:00<00:16, 205MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   3%|▏     | 105M/3.50G [00:00<00:16, 207MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   4%|▏     | 126M/3.50G [00:00<00:16, 207MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   4%|▎     | 147M/3.50G [00:00<00:16, 207MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   5%|▎     | 178M/3.50G [00:00<00:15, 208MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   6%|▎     | 199M/3.50G [00:00<00:15, 208MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   6%|▍     | 220M/3.50G [00:01<00:16, 205MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   7%|▍     | 241M/3.50G [00:01<00:15, 205MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   8%|▍     | 273M/3.50G [00:01<00:15, 207MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   8%|▌     | 294M/3.50G [00:01<00:15, 206MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   9%|▌     | 315M/3.50G [00:01<00:15, 206MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  10%|▌     | 346M/3.50G [00:01<00:15, 209MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  10%|▋     | 367M/3.50G [00:01<00:15, 208MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  11%|▋     | 388M/3.50G [00:01<00:15, 204MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  12%|▋     | 409M/3.50G [00:01<00:15, 204MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  13%|▊     | 440M/3.50G [00:02<00:14, 205MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  13%|▊     | 461M/3.50G [00:02<00:14, 203MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  14%|▊     | 482M/3.50G [00:02<00:14, 203MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  14%|▊     | 503M/3.50G [00:02<00:14, 201MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  15%|▉     | 524M/3.50G [00:02<00:14, 201MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  16%|▉     | 545M/3.50G [00:02<00:14, 202MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  16%|▉     | 577M/3.50G [00:02<00:14, 206MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  17%|█     | 608M/3.50G [00:02<00:13, 209MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  18%|█     | 629M/3.50G [00:03<00:13, 205MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  19%|█▏    | 661M/3.50G [00:03<00:13, 207MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  19%|█▏    | 682M/3.50G [00:03<00:13, 207MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  20%|█▏    | 703M/3.50G [00:03<00:13, 207MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  21%|█▏    | 724M/3.50G [00:03<00:13, 208MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  22%|█▎    | 755M/3.50G [00:03<00:13, 210MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  22%|█▎    | 786M/3.50G [00:03<00:12, 210MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  23%|█▍    | 807M/3.50G [00:03<00:12, 209MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  24%|█▍    | 828M/3.50G [00:04<00:12, 209MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  24%|█▍    | 849M/3.50G [00:04<00:12, 208MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  25%|█▍    | 870M/3.50G [00:04<00:12, 207MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  25%|█▌    | 891M/3.50G [00:04<00:12, 207MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  26%|█▌    | 912M/3.50G [00:04<00:12, 207MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  27%|█▌    | 933M/3.50G [00:04<00:12, 206MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  27%|█▋    | 954M/3.50G [00:04<00:12, 204MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  28%|█▋    | 975M/3.50G [00:04<00:12, 204MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  28%|█▋    | 996M/3.50G [00:04<00:12, 206MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  29%|█▍   | 1.02G/3.50G [00:04<00:12, 204MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  30%|█▍   | 1.04G/3.50G [00:05<00:12, 204MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  30%|█▌   | 1.06G/3.50G [00:05<00:12, 203MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  31%|█▌   | 1.08G/3.50G [00:05<00:12, 201MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  31%|█▌   | 1.10G/3.50G [00:05<00:11, 202MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  32%|█▌   | 1.12G/3.50G [00:05<00:11, 200MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  33%|█▋   | 1.14G/3.50G [00:05<00:11, 201MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  33%|█▋   | 1.16G/3.50G [00:05<00:11, 201MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  34%|█▋   | 1.18G/3.50G [00:05<00:11, 202MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  34%|█▋   | 1.21G/3.50G [00:05<00:11, 201MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  35%|█▊   | 1.23G/3.50G [00:05<00:11, 201MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  36%|█▊   | 1.25G/3.50G [00:06<00:11, 202MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  36%|█▊   | 1.27G/3.50G [00:06<00:11, 202MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  37%|█▊   | 1.29G/3.50G [00:06<00:10, 203MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  37%|█▊   | 1.31G/3.50G [00:06<00:10, 201MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  38%|█▉   | 1.33G/3.50G [00:06<00:10, 201MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  39%|█▉   | 1.35G/3.50G [00:06<00:10, 202MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  39%|█▉   | 1.37G/3.50G [00:06<00:10, 203MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  40%|█▉   | 1.39G/3.50G [00:06<00:10, 203MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  40%|██   | 1.42G/3.50G [00:06<00:10, 202MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  41%|██   | 1.44G/3.50G [00:07<00:10, 201MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  42%|██   | 1.46G/3.50G [00:07<00:10, 201MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  42%|██   | 1.48G/3.50G [00:07<00:10, 201MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  43%|██▏  | 1.50G/3.50G [00:07<00:09, 202MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  43%|██▏  | 1.52G/3.50G [00:07<00:09, 201MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  44%|██▏  | 1.54G/3.50G [00:07<00:09, 200MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  45%|██▏  | 1.56G/3.50G [00:07<00:09, 201MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  45%|██▎  | 1.58G/3.50G [00:07<00:09, 202MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  46%|██▎  | 1.60G/3.50G [00:07<00:09, 203MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  46%|██▎  | 1.63G/3.50G [00:07<00:09, 205MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  47%|██▎  | 1.65G/3.50G [00:08<00:09, 206MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  48%|██▍  | 1.67G/3.50G [00:08<00:08, 206MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  48%|██▍  | 1.69G/3.50G [00:08<00:08, 207MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  49%|██▍  | 1.72G/3.50G [00:08<00:08, 206MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  50%|██▌  | 1.75G/3.50G [00:08<00:08, 208MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  51%|██▌  | 1.77G/3.50G [00:08<00:08, 207MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  51%|██▌  | 1.79G/3.50G [00:08<00:08, 206MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  52%|██▌  | 1.81G/3.50G [00:08<00:08, 206MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  52%|██▌  | 1.84G/3.50G [00:08<00:08, 207MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  53%|██▋  | 1.86G/3.50G [00:09<00:07, 207MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  54%|██▋  | 1.88G/3.50G [00:09<00:07, 206MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  54%|██▋  | 1.90G/3.50G [00:09<00:07, 207MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  55%|██▋  | 1.92G/3.50G [00:09<00:07, 205MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  55%|██▊  | 1.94G/3.50G [00:09<00:07, 205MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  56%|██▊  | 1.97G/3.50G [00:09<00:07, 208MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  57%|██▊  | 1.99G/3.50G [00:09<00:07, 207MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  58%|██▉  | 2.01G/3.50G [00:09<00:07, 206MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  58%|██▉  | 2.03G/3.50G [00:09<00:07, 205MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  59%|██▉  | 2.07G/3.50G [00:10<00:06, 207MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  60%|██▉  | 2.09G/3.50G [00:10<00:06, 206MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  60%|███  | 2.11G/3.50G [00:10<00:06, 207MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  61%|███  | 2.14G/3.50G [00:10<00:06, 206MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  62%|███  | 2.17G/3.50G [00:10<00:06, 208MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  63%|███▏ | 2.19G/3.50G [00:10<00:06, 207MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  63%|███▏ | 2.21G/3.50G [00:11<00:09, 133MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  64%|███▏ | 2.23G/3.50G [00:11<00:08, 147MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  64%|███▏ | 2.25G/3.50G [00:11<00:07, 160MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  65%|███▎ | 2.28G/3.50G [00:11<00:07, 172MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  66%|███▎ | 2.30G/3.50G [00:11<00:06, 180MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  67%|███▎ | 2.33G/3.50G [00:11<00:06, 191MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  67%|███▎ | 2.35G/3.50G [00:11<00:05, 195MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  68%|███▍ | 2.37G/3.50G [00:11<00:05, 199MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  68%|███▍ | 2.39G/3.50G [00:11<00:05, 201MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  69%|███▍ | 2.41G/3.50G [00:11<00:05, 203MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  69%|███▍ | 2.43G/3.50G [00:12<00:05, 204MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  70%|███▌ | 2.45G/3.50G [00:12<00:05, 205MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  71%|███▌ | 2.47G/3.50G [00:12<00:04, 206MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  71%|███▌ | 2.50G/3.50G [00:12<00:04, 206MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  72%|███▌ | 2.52G/3.50G [00:12<00:04, 206MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  73%|███▋ | 2.55G/3.50G [00:12<00:04, 208MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  73%|███▋ | 2.57G/3.50G [00:12<00:04, 208MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  74%|███▋ | 2.59G/3.50G [00:12<00:04, 208MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  75%|███▋ | 2.61G/3.50G [00:12<00:04, 208MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  75%|███▊ | 2.64G/3.50G [00:13<00:04, 206MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  76%|███▊ | 2.67G/3.50G [00:13<00:04, 206MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  77%|███▊ | 2.69G/3.50G [00:13<00:03, 205MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  78%|███▉ | 2.72G/3.50G [00:13<00:03, 205MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  78%|███▉ | 2.74G/3.50G [00:13<00:03, 204MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  79%|███▉ | 2.76G/3.50G [00:13<00:03, 190MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  79%|███▉ | 2.78G/3.50G [00:13<00:03, 194MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  80%|███▉ | 2.80G/3.50G [00:13<00:03, 196MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  81%|████ | 2.82G/3.50G [00:13<00:03, 197MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  81%|████ | 2.84G/3.50G [00:14<00:03, 198MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  82%|████ | 2.86G/3.50G [00:14<00:03, 200MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  82%|████ | 2.88G/3.50G [00:14<00:03, 201MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  83%|████▏| 2.90G/3.50G [00:14<00:02, 202MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  84%|████▏| 2.93G/3.50G [00:14<00:02, 200MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  84%|████▏| 2.95G/3.50G [00:14<00:02, 201MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  85%|████▏| 2.97G/3.50G [00:14<00:02, 199MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  85%|████▎| 2.99G/3.50G [00:14<00:02, 200MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  86%|████▎| 3.01G/3.50G [00:14<00:02, 200MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  87%|████▎| 3.03G/3.50G [00:15<00:02, 202MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  87%|████▎| 3.05G/3.50G [00:15<00:02, 202MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  88%|████▍| 3.07G/3.50G [00:15<00:02, 201MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  88%|████▍| 3.09G/3.50G [00:15<00:02, 198MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  89%|███▌| 3.11G/3.50G [00:18<00:17, 22.0MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  90%|███▌| 3.14G/3.50G [00:18<00:12, 29.5MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  90%|███▌| 3.16G/3.50G [00:18<00:08, 39.7MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  91%|███▋| 3.18G/3.50G [00:18<00:06, 52.3MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  91%|███▋| 3.20G/3.50G [00:18<00:04, 67.1MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  92%|███▋| 3.22G/3.50G [00:18<00:03, 84.1MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  93%|████▋| 3.25G/3.50G [00:18<00:02, 110MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  94%|████▋| 3.28G/3.50G [00:19<00:01, 133MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  94%|████▋| 3.30G/3.50G [00:19<00:01, 144MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  95%|████▋| 3.32G/3.50G [00:19<00:01, 156MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  96%|████▊| 3.34G/3.50G [00:19<00:00, 164MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  96%|████▊| 3.37G/3.50G [00:19<00:00, 172MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  97%|████▊| 3.39G/3.50G [00:19<00:00, 179MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  97%|████▊| 3.41G/3.50G [00:19<00:00, 185MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  98%|████▉| 3.43G/3.50G [00:19<00:00, 187MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  99%|████▉| 3.45G/3.50G [00:19<00:00, 190MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  99%|████▉| 3.47G/3.50G [00:20<00:00, 193MB/s]\u001b[A\nmodel-00002-of-00002.safetensors: 100%|█████| 3.50G/3.50G [00:20<00:00, 173MB/s]\u001b[A\nDownloading shards: 100%|█████████████████████████| 2/2 [01:09<00:00, 34.95s/it]\nLoading checkpoint shards: 100%|██████████████████| 2/2 [00:06<00:00,  3.40s/it]\ngeneration_config.json: 100%|██████████████████| 200/200 [00:00<00:00, 1.01MB/s]\n2024-08-01 19:58:58.005 Uncaught app exception\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/peft/config.py\", line 144, in from_pretrained\n    config_file = hf_hub_download(\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 106, in _inner_fn\n    validate_repo_id(arg_value)\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 154, in validate_repo_id\n    raise HFValidationError(\nhuggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/kaggle/input/fine-tuned-model2'. Use `repo_type` argument if needed.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 75, in exec_func_with_error_handling\n    result = func()\n  File \"/opt/conda/lib/python3.10/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 574, in code_to_exec\n    exec(code, module.__dict__)\n  File \"/kaggle/working/streamlit_app_2.py\", line 137, in <module>\n    model, tokenizer, emotions, emotion_classifier = load_model_and_tokenizer()\n  File \"/opt/conda/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 168, in wrapper\n    return cached_func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 197, in __call__\n    return self._get_or_create_cached_value(args, kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 224, in _get_or_create_cached_value\n    return self._handle_cache_miss(cache, value_key, func_args, func_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 280, in _handle_cache_miss\n    computed_value = self._info.func(*func_args, **func_kwargs)\n  File \"/kaggle/working/streamlit_app_2.py\", line 114, in load_model_and_tokenizer\n    lora_config = LoraConfig.from_pretrained('/kaggle/input/fine-tuned-model2')\n  File \"/opt/conda/lib/python3.10/site-packages/peft/config.py\", line 148, in from_pretrained\n    raise ValueError(f\"Can't find '{CONFIG_NAME}' at '{pretrained_model_name_or_path}'\") from exc\nValueError: Can't find 'adapter_config.json' at '/kaggle/input/fine-tuned-model2'\n","output_type":"stream"}]},{"cell_type":"code","source":"!ngrok authtoken 2jb86JKOHKjdCaoHKnPIeqPbJJ9_6Zrx6tHZQeLacbEwNFuCQ","metadata":{"execution":{"iopub.status.busy":"2024-08-01T19:56:52.845386Z","iopub.execute_input":"2024-08-01T19:56:52.845766Z","iopub.status.idle":"2024-08-01T19:56:54.829456Z","shell.execute_reply.started":"2024-08-01T19:56:52.845733Z","shell.execute_reply":"2024-08-01T19:56:54.828377Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml                                \n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **LangChain with context**","metadata":{}},{"cell_type":"code","source":"from langchain import LLMChain, PromptTemplate\nfrom langchain.memory.buffer import ConversationBufferMemory\nfrom langchain.schema.runnable import RunnablePassthrough\nfrom langchain_core.output_parsers import StrOutputParser\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nfrom langchain import HuggingFacePipeline, PromptTemplate, LLMChain\nfrom peft import PeftModel, PeftConfig\nimport torch\n\nclass StoryCreativityChain:\n    def __init__(self, model, tokenizer):\n       \n        self.llmPipeline = pipeline(\"text-generation\",\n                                    model=model,\n                                    tokenizer=tokenizer,\n                                    torch_dtype=torch.float16,\n                                    device_map=\"auto\",\n                                    max_new_tokens=1000,\n                                    do_sample=True,\n                                    top_k=30,\n                                    num_return_sequences=1,\n                                    eos_token_id=tokenizer.eos_token_id\n                                    )\n        self.llm = HuggingFacePipeline(pipeline=self.llmPipeline, model_kwargs={'temperature': 0.7, 'max_length': 5, 'top_k': 50})\n        \n    def getPromptFromTemplate(self):\n        system_prompt = \"\"\"You are a creative story assistant. Your task is to help the user generate and write stories.\n        Stick to the context of story creativity. If the user asks anything out of context, other than story generation or writing, politely inform them that you\n        can only help with story-related queries and cannot help with anything else. Don't answer anything out of context. Provide detailed and imaginative responses to help the user.\"\"\"\n\n        B_INST, E_INST = \"[INST]\", \"[/INST]\"\n        B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n        SYSTEM_PROMPT1 = B_SYS + system_prompt + E_SYS\n\n        instruction = \"\"\"\n        History: {history} \\n\n        Context: {context} \\n\n        User: {question}\"\"\"\n\n        prompt_template = B_INST + SYSTEM_PROMPT1 + instruction + E_INST\n        prompt = PromptTemplate(input_variables=[\"history\", \"question\", \"context\"], template=prompt_template)\n\n        return prompt\n\n    def getNewChain(self, usermood):\n        prompt = self.getPromptFromTemplate()\n        memory = ConversationBufferMemory(input_key=\"question\", memory_key=\"history\", max_len=5)\n\n        # Initialize LLMChain with proper parameters\n        llm_chain = LLMChain(prompt=prompt, llm=self.llm, verbose=True, memory=memory, output_parser=CustomOutputParser())\n\n        # Return a callable that processes inputs using the chain\n        def run_chain(inputs):\n            # Ensure the inputs are correctly provided\n            context = inputs.get(\"context\", \"\")\n            question = inputs.get(\"question\", \"\")\n            return llm_chain.run({\"history\": \"\", \"context\": context, \"question\": question})\n\n        return run_chain\n\nclass CustomOutputParser(StrOutputParser):\n    def parse(self, response: str):\n        return response.split('[/INST]')[-1].strip()\n\nif __name__ == \"__main__\":\n    user_input = \"Tell me a funny story\"\n#     \"Can you tell me recipe of pasta?\"\n    mood = predict_emotion(user_input)  # Replace with actual mood detection logic\n    print(f'Analyzed mood: {mood}')\n    \n    story_chain = StoryCreativityChain(model, tokenizer)\n    chain = story_chain.getNewChain(mood)\n\n    # Simulate user interaction\n    response = chain({\"question\": user_input, \"context\": mood})\n    print(f'Generated story: {response}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"response = chain({\"question\": \"Continue\", \"context\": mood})\nprint(f'Generated story: {response}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"response = chain({\"question\": \"Who was Dr. Doom-a-Lot?\", \"context\": mood})\nprint(f'Generated story: {response}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"response = chain({\"question\": \"Can you tell me again what the story was about?\", \"context\": mood})\nprint(f'Generated story: {response}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n# from peft import LoraConfig, get_peft_model\n# import torch\n\n# class StoryCreativityChain:\n#     def __init__(self, model, tokenizer):\n\n#         self.pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n\n#     def get_prompt_template(self):\n#         system_prompt = \"\"\"You are a creative story assistant. Your task is to help the user generate and write stories.\n#         Stick to the context of story creativity. If the user asks anything out of context, politely inform them that you\n#         can only help with story-related queries. Provide detailed and imaginative responses to help the user.\"\"\"\n\n#         B_INST, E_INST = \"[INST]\", \"[/INST]\"\n#         B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n#         SYSTEM_PROMPT1 = B_SYS + system_prompt + E_SYS\n\n#         instruction = \"\"\"\n#         History: {history} \\n\n#         Context: {context} \\n\n#         User: {question}\"\"\"\n\n#         prompt_template = B_INST + SYSTEM_PROMPT1 + instruction + E_INST\n#         return prompt_template\n\n#     def run_chain(self, user_mood, user_input):\n#         prompt_template = self.get_prompt_template()\n#         prompt = prompt_template.format(history=\"\", context=user_mood, question=user_input)\n\n#         # Generate a response using the Hugging Face pipeline\n#         response = self.pipeline(prompt, max_length=1000, num_return_sequences=1)[0]['generated_text']\n#         return response\n\n# # Initialize the story chain\n# story_chain = StoryCreativityChain(model, tokenizer)\n\n# # Simulate user input and mood\n# user_input = \"Tell me a funny story\"\n# mood = predict_emotion(user_input)  # Replace with actual mood detection logic\n\n# # Run the chain\n# response = story_chain.run_chain(mood, user_input)\n# print(f'Generated story: {response}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Run the chain\n# response = story_chain.run_chain(mood, \"Tell me recipe of pasta\")\n# print(f'Generated story: {response}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
